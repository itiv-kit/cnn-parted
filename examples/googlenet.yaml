neural-network:
  name: googlenet
  input-size: [ 1, 3, 224, 224 ]

accuracy:
  device : "cuda"
  bits: [32, 8]
  calibration:
    samples: null # null sets samples to all
    file: './calibrations/googlenet_quant_calib.pkl'
  retraining:
    epochs: 2
  datasets:
    calibrate:
      type: imagenet
      kind: 'imagefolder'
      path: '/tools/datasets/imagenet/val_images'
      sample_limit: null # number of validation dataset samples to test for each individual
      batch_size: 64
      randomize: True
    validation:
      type: imagenet
      kind: 'imagefolder'
      path: '/tools/datasets/imagenet/val_images'
      sample_limit: 8192 # number of validation dataset samples to test for each individual
      batch_size: 256
      randomize: True
    train:
      type: imagenet
      kind: 'webdataset'
      path: '/tools/datasets/imagenet/train/imagenet-train-{0000..0136}.tar'
      total_samples: 1281167
      batch_size: 256
      sample_limit: null

sensor:
  timeloop:
    layer: conv2d
    accelerator: simba_like
    frequency: 500000000
    mapper:
      optimization-metrics: [ delay, energy ]
      live-status: False
      num-threads: 8
      timeout: 0
      victory-condition: 100
      algorithm: linear-pruned

link:
  data_bit_width: 16
  fps: 25
  ethernet:
    eth_mode : "BASE1000-T"
    cable_len_m : 5
    enable_eee : False
    eee_lmi_ratio : 0.1
    eee_toff_ms : 0

edge:
  device : "cpu"
  max_threads : 10
  num_runs : 500

constraints:
  max_out_size : 200000
