constraints: {max_out_size: 20000000,  max_memory_size: 600000000, word_width: 16}

optimization-objectives:
  component: 0
  metric: latency

neural-network:
  input-size: [1, 3, 224, 224]
  name: googlenet

accuracy:
  device : "cuda"
  bits: [32, 8]
  calibration:
    samples: null # null sets samples to all
    file: './calibrations/googlenet_quant_calib.pkl'
  retraining:
    epochs: 2
  datasets:
    calibrate:
      type: imagenet
      kind: 'imagefolder'
      path: '/tools/datasets/imagenet/val_images'
      sample_limit: null # number of validation dataset samples to test for each individual
      batch_size: 64
      randomize: True
    validation:
      type: imagenet
      kind: 'imagefolder'
      path: '/tools/datasets/imagenet/val_images'
      sample_limit: 8192 # number of validation dataset samples to test for each individual
      batch_size: 256
      randomize: True
    train:
      type: imagenet
      kind: 'webdataset'
      path: '/tools/datasets/imagenet/train/imagenet-train-{0000..0136}.tar'
      total_samples: 1281167
      batch_size: 256
      sample_limit: null

components:
  - id: 2
    max_memory_size: 6000000
    name: sensor #optional
    mnsim:
      conf_path: '/configs/mnsim_configs/SimConfig.ini'
  - id: 1
    max_out_size: 20000000
    data_bit_width: 8
    noi:
      noi_mode: UCIe
      width: 16
      data_rate: 32
      latency_ns: 2 # including D2D Adapter and PHY
      power_bit_pj: 0.5
    fps: 25
  - id: 0
    max_memory_size: 6000000
    timeloop:
      accelerator: simba_like
      frequency: 500000000
      layer: conv2d
      mapper:
        algorithm: linear-pruned
        live-status: false
        num-threads: 8
        timeout: 0
        victory-condition: 100
